//! llama.cpp server integration using OpenAI-compatible Chat Completions.

pub mod client;

pub use client::LlamaCppClient;
